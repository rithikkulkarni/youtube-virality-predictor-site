<!DOCTYPE HTML>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Research</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1><a href="index.html">Back to Home</a></h1>
						<!-- <nav>
							<a href="#menu">Menu</a>
						</nav> -->
					</header>

				<!-- Menu -->
					<!-- <nav id="menu">
						<div class="inner">
							<h2>Menu</h2>
							<ul class="links">
								<li><a href="index.html">Home</a></li>
								<li><a href="generic.html">Generic</a></li>
								<li><a href="elements.html">Elements</a></li>
								<li><a href="#">Log In</a></li>
								<li><a href="#">Sign Up</a></li>
							</ul>
							<a href="#" class="close">Close</a>
						</div>
					</nav> -->

				<!-- Wrapper -->
					<section id="wrapper">
						<header>
							<div class="inner">
								<h2>Research</h2>
								<p>How does this YouTube Video Classifier work?</p>
							</div>
						</header>

						<!-- Content -->
							<div class="wrapper">
								<div class="inner">

									<section>
										<h3 class="major">Psychological Background</h3>
										<p>
											The psychological impact of thumbnails and titles plays a critical role in shaping viewer behavior on YouTube. Visual features like brightness, edge density, and color contrast capture attention by leveraging principles of visual saliency—our brains are hardwired to notice high-contrast or detailed areas quickly. Titles, meanwhile, trigger cognitive biases through emotional language, urgency, or curiosity—such as in the use of clickbait phrasing or questions—which tap into the psychological phenomenon known as the “curiosity gap.” These elements influence not only whether users notice a video but whether they feel compelled to click, making them central to predicting virality and optimizing content performance before a video is even published.
										</p>
										<blockquote>
											<strong>
												The visual complexity of an image, as perceived by edge density and local color contrast, increases the likelihood of gaze fixation in the first few milliseconds.
											</strong>
											<br>
											- Nuthmann & Henderson, 2010
										</blockquote>
									</section>

									<section>
										<h3 class="major">Important Feature Genres</h3>
										<div class="row">
											<div class="col-4 col-12-medium">
												<h4>Visual Features</h4>
												<ul>
													<li>RGB</li>
													<li>Brightness</li>
													<li>Contrast</li>
													<li>Dominant Color Hue</li>
													<li>Thumbnail Edge Density</li>
												</ul>
												<!-- <h4>Alternate</h4>
												<ul class="alt">
													<li>Dolor pulvinar etiam.</li>
													<li>Sagittis adipiscing.</li>
													<li>Felis enim feugiat.</li>
												</ul> -->
											</div>
											<div class="col-4 col-12-medium">
												<h4>Text Features</h4>
												<ul>
													<li>Sentiment</li>
													<li>Length</li>
													<li>Capitalization/Punctuation</li>
													<li>Clickbait Score</li>
													<li>Readability</li>
												</ul>
												<!-- <h4>Icons</h4>
												<ul class="icons">
													<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
													<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
													<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
													<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
												</ul> -->
											</div>
										</div>

										<h4>Clickbait Score Calculation</h4>
										<pre><code>def compute_clickbait_score(text: str) -> float:
    clickbait_words = {
        "amazing", "shocking", "unbelievable", "top", "ultimate", "must",
        "insane", "you won’t believe", "secret", "revealed", "hack"
    }
    words = text.split()
    clickbait_score = sum(word.lower() in clickbait_words for word in words)
    return clickbait_score;</code></pre>
										<p>
											The clickbait score is a simple metric that counts the number of clickbait words in a given text. It can be useful for identifying potentially misleading or sensational content.
										</p>
										<h4>Readability Score Calculation</h4>
										<pre><code>def flesch_reading_ease(text):
    sentences = re.split(r'[.!?]+', text)
    sentences = [s.strip() for s in sentences if s.strip()]
    
    words = re.findall(r'\w+', text)
    num_sentences = max(1, len(sentences))
    num_words = max(1, len(words))
    num_syllables = sum(count_syllables(word) for word in words)
    
    asl = num_words / num_sentences  # Average sentence length
    asw = num_syllables / num_words  # Average syllables per word

    # Flesch Reading Ease formula
    score = 206.835 - (1.015 * asl) - (84.6 * asw)
    return round(score, 2)</code></pre>
										<p>
											The Flesch Reading Ease score is a widely used readability test that evaluates the complexity of English texts. It considers the average sentence length and the average number of syllables per word to produce a score between 0 and 100, where higher scores indicate easier readability.
										</p>
										<!-- <h4>Actions</h4>
										<div class="row">
											<div class="col-6 col-12-medium">
												<ul class="actions">
													<li><a href="#" class="button primary">Default</a></li>
													<li><a href="#" class="button">Default</a></li>
												</ul>
												<ul class="actions small">
													<li><a href="#" class="button primary small">Small</a></li>
													<li><a href="#" class="button small">Small</a></li>
												</ul>
												<ul class="actions stacked">
													<li><a href="#" class="button primary">Default</a></li>
													<li><a href="#" class="button">Default</a></li>
												</ul>
												<ul class="actions stacked small">
													<li><a href="#" class="button primary small">Small</a></li>
													<li><a href="#" class="button small">Small</a></li>
												</ul>
											</div>
											<div class="col-6 col-12-medium">
												<ul class="actions stacked">
													<li><a href="#" class="button primary fit">Default</a></li>
													<li><a href="#" class="button fit">Default</a></li>
												</ul>
												<ul class="actions stacked small">
													<li><a href="#" class="button primary small fit">Small</a></li>
													<li><a href="#" class="button small fit">Small</a></li>
												</ul>
											</div>
										</div> -->
										<!-- <h4>Pagination</h4>
										<ul class="pagination">
											<li><span class="button small disabled">Prev</span></li>
											<li><a href="#" class="page active">1</a></li>
											<li><a href="#" class="page">2</a></li>
											<li><a href="#" class="page">3</a></li>
											<li><span>&hellip;</span></li>
											<li><a href="#" class="page">8</a></li>
											<li><a href="#" class="page">9</a></li>
											<li><a href="#" class="page">10</a></li>
											<li><a href="#" class="button small">Next</a></li>
										</ul> -->
									</section>
									<section>
										<h3 class="major">Training Dataset</h3>
										<p>
											The training dataset consists of over 15,000 YouTube videos taken from <em>somewhat</em> popular channels that have been judged by human experts to be "reliant on the YouTube algorithm." This is important to ensure that the model learns from content that is aiming to optimize for virality and engagement, rather than content that performs purely due to an already-established audience or brand. The dataset includes a diverse range of topics and styles, ensuring that the model can generalize well across different types of content.
										</p>
										<h4 style="text-align:center; width:100%;">Training Channels</h4>
										<div class="row" style="display: flex; flex-wrap: wrap;">
											<div class="col-3 col-12-medium" style="flex: 1 1 0;">
												<ul>
													<li>French Cooking Academy</li>
													<li>Cooking Buddies</li>
													<li>Glock9</li>
													<li>Phisnom</li>
													<li>BrainCraft</li>
													<li>Jordan Harrod</li>
												</ul>
											</div>
											<div class="col-3 col-12-medium" style="flex: 1 1 0;">
												<ul>
													<li>Nostalgia Nerd</li>
													<li>EEVblog</li>
													<li>Lainey Ostrom</li>
													<li>Kristin Johns</li>
													<li>iGoBart</li>
													<li>Ghib Ojisan</li>
												</ul>
											</div>
											<div class="col-3 col-12-medium" style="flex: 1 1 0;">
												<ul>
													<li>Vo2maxProductions</li>
													<li>Heather Robertson</li>
													<li>Alexrainbirdmusic</li>
													<li>Megan Davies</li>
													<li>The Valleyfolk</li>
													<li>Chris Fleming</li>
												</ul>
											</div>
											<div class="col-3 col-12-medium" style="flex: 1 1 0;">
												<ul>
													<li>Xyla Foxlin</li>
													<li>Potholer54</li>
													<li>Rule1Investing</li>
													<li>Ben Felix</li>
													<li>Griffon Ramsey</li>
													<li>Proko</li>
												</ul>
											</div>
										</div>
									</section>

									<section>
										<h3 class="major">Model Architecture</h3>
										<p>
											The deployed model powering this web service was trained to recognize patterns in pre-publication metadata that correlate with higher likelihoods of YouTube virality. Unlike models that rely on post-publication signals like early view counts, this system uses only information available before a video is posted—such as title text, description, tags, and thumbnail image—to make its predictions. It leverages a Random Forest classifier enhanced with SMOTE (Synthetic Minority Oversampling Technique) which creates synthetic minority class examples to address class imbalance, ensuring that the model remains sensitive to underrepresented viral examples. By focusing on psychologically and behaviorally relevant features—such as visual salience in thumbnails or curiosity-inducing phrasing in titles—the model supports creators in optimizing their content ahead of time, with minimal technical overhead.
										</p>
										<div class="row" style="display: flex; flex-wrap: wrap; align-items: flex-start;">
											<div class="col-6 col-12-medium" style="flex: 1 1 0; display: flex; flex-direction: column; align-items: center;">
												<h4 style="text-align: center;">Random Forest Classifier</h4>
												<img src="images/randomforestdiagram.jpg" alt="Random Forest Diagram" style="width: 100%;">
											</div>
											<div class="col-6 col-12-medium" style="flex: 1 1 0; display: flex; flex-direction: column; align-items: center;">
												<h4 style="text-align: center;">SMOTE</h4>
												<img src="images/smotevisual.JPG" alt="SMOTE Diagram" style="width: 100%;">
											</div>
										</div>
									</section>
								</div>
							</div>
					</section>
			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>